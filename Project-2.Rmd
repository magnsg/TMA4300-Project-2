---
title: "TMA4300 Project 2"
author: "Magnus Grytten & Petter J. Gudbrandsen"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, results = FALSE, message = FALSE, warning = FALSE}
# Import classes
library("INLA")
library(invgamma)
library(matlib)
library(MASS)

# Load data 
load("rain.rda") # set working directory correctly
```

# Problem 1

## a)
Explore the Tokyo rainfall dataset, plot the response as a function of t, and describe any patterns that you see.

```{r}
plot(rain$day, rain$n.rain, xlab = 'Day of the year', ylab = '# years with rain')
```
The plot shows the number of days with rain in each day of the year over a period of 39 years.

During the winter period there is little rain. It increases during the spring. After that it seems to have two 'down' bumps during the summer. During the autumn, from about day 275 and until new year, it decreases.

The points seem to follow a continuous function with a similar error around it throughout the year.

## b)
The likelihood of $y_t$ given $\pi(\tau_t)$ is given to be a binomial distribution.
$$
p(y_t|\pi(\tau_t)) = \binom{n_t}{y_t} \pi(\tau_t)^{y_t}(1 - \pi(\tau_t))^{n_t - y_t}
$$

## c)
To find the conditional $p(\sigma^2 | \boldsymbol{y}, \boldsymbol{\tau})$, we first use Bayes' theorem and the chain rule for conditional probability to obtain,
$$
\begin{aligned}
p(\sigma^2 | \boldsymbol{y}, \boldsymbol{\tau})
\propto& p(\boldsymbol{y}, \boldsymbol{\tau} | \sigma^2) \cdot p(\sigma^2) \\
=&
p(\boldsymbol{y} | \boldsymbol{\tau}, \sigma^2) \cdot p(\boldsymbol{\tau} | \sigma^2) \cdot p(\sigma^2) \\
=&
p(\boldsymbol{y} | \boldsymbol{\tau}) \cdot p(\boldsymbol{\tau} | \sigma^2) \cdot p(\sigma^2) \\
=&
\prod_{t=1}^T \binom{n_t}{y_t} \pi(\tau_t)^{y_t}(1 - \pi(\tau_t))^{n_t - y_t} \\
\cdot&
\prod_{t=2}^T \frac{1}{\sigma_u} e^{-\frac{1}{2\sigma_u^2} (\tau_t - \tau_{t-1})^2} \\
\cdot&
\frac{\beta^\alpha}{\Gamma(\alpha)} (\frac{1}{\sigma_u^2})^{\alpha + 1} e^{-\frac{\beta}{\sigma_u^2}} \\
\end{aligned}
$$
We remove factors without $\sigma_u$.
$$
\begin{aligned}
\propto &
\prod_{t=2}^T \frac{1}{\sigma_u} e^{-\frac{1}{2\sigma_u^2} (\tau_t - \tau_{t-1})^2}
\cdot
(\frac{1}{\sigma_u^2})^{\alpha + 1}
\cdot
e^{-\frac{\beta}{\sigma_u^2}} \\
= &
\frac{1}{\sigma_u^{T-1}} e^{-\frac{1}{2\sigma_u^2}  \boldsymbol{\tau}^\intercal \boldsymbol{Q\tau}}
\cdot
(\frac{1}{\sigma_u^{2}})^{\alpha + 1}
\cdot
e^{-\frac{\beta}{\sigma_u^2}} \\
= &
(\frac{1}{\sigma_u^2})^{\alpha + 1 + \frac{T-1}{2}} e^{-\frac{1}{2\sigma_u^2}  (\boldsymbol{\tau}^\intercal \boldsymbol{Q\tau} + \beta)} \\
\end{aligned}
$$
In the last expression we recognize the core of an inverse gamma distribution:
$$
IG \sim (\alpha + \frac{T-1}{2}, \frac{\boldsymbol{\tau}^\intercal \boldsymbol{Q\tau} + \beta}{2}) \\
$$
for shape $\alpha$ and rate $\beta$.

## d)
Since assume conditional independence among the $y_t|\tau_t$ we have,
$$
\begin{aligned}
p(\boldsymbol{y} |\boldsymbol{\tau}) = \prod_{t=1}^T p(y_t|\tau_t) = 
p(\boldsymbol{y_{I}} |\boldsymbol{\tau_{I}})
\cdot p(\boldsymbol{y_{-I}} |\boldsymbol{\tau_{-I}})
\end{aligned}
$$


To find the acceptance probability we start by looking at the posterior $p(\boldsymbol{\tau}, \sigma^2 | \boldsymbol{y})$, were we again use the Bayes' theorem and the chain rule, as well as the expression above to find,
$$
\begin{aligned}
p(\boldsymbol{\tau}, \sigma^2 | \boldsymbol{y})
\propto &
p(\boldsymbol{y} | \boldsymbol{\tau}, \sigma^2) \cdot p(\boldsymbol{\tau}, \sigma^2) \\
= &
p(\boldsymbol{y} | \boldsymbol{\tau}) \cdot p(\boldsymbol{\tau} | \sigma^2) \cdot p(\sigma^2) \\
= &
p(\boldsymbol{y}_I | \boldsymbol{\tau}_I) 
\cdot
p(\boldsymbol{y}_{-I} | \boldsymbol{\tau}_{-I}) 
\cdot 
p(\boldsymbol{\tau}_{-I} | \sigma^2) 
\cdot 
p(\boldsymbol{\tau}_{I} | \boldsymbol{\tau}_{-I}, \sigma^2) 
\cdot 
p(\sigma^2) \\
\end{aligned}
$$
The acceptance probability is given by,
$$
\begin{aligned}
\alpha
= min(1, 
\frac
{p(\boldsymbol{\tau'}_I, \sigma^2 | \boldsymbol{y}) 
\cdot 
p(\boldsymbol{\tau}_I | \boldsymbol{\tau'}_{-I}, \sigma^2)}
{p(\boldsymbol{\tau}_I, \sigma^2 | \boldsymbol{y}) 
\cdot 
p(\boldsymbol{\tau'}_I | \boldsymbol{\tau}_{-I}, \sigma^2)}) 
\end{aligned}
$$
Inserting the expression for $p(\boldsymbol{\tau}, \sigma^2 | \boldsymbol{y})$ in the the expression for the acceptance probability we get,
$$
\frac
{p(\boldsymbol{\tau'}_I, \sigma^2 | \boldsymbol{y}) 
\cdot 
p(\boldsymbol{\tau}_I | \boldsymbol{\tau'}_{-I}, \sigma^2)}
{p(\boldsymbol{\tau}_I, \sigma^2 | \boldsymbol{y}) 
\cdot 
p(\boldsymbol{\tau'}_I | \boldsymbol{\tau}_{-I}, \sigma^2)} \\
$$
$$
=\frac
{p(\boldsymbol{y}_I | \boldsymbol{\tau'}_I) 
\cdot
p(\boldsymbol{y}_{-I} | \boldsymbol{\tau'}_{-I}) 
\cdot 
p(\boldsymbol{\tau'}_{-I} | \sigma^2) 
\cdot 
p(\boldsymbol{\tau'}_{I} | \boldsymbol{\tau'}_{-I}, \sigma^2) 
\cdot 
p(\sigma^2) 
\cdot 
p(\boldsymbol{\tau}_I | \boldsymbol{\tau'}_{-I}, \sigma^2)}
{p(\boldsymbol{y}_I | \boldsymbol{\tau}_I) 
\cdot
p(\boldsymbol{y}_{-I} | \boldsymbol{\tau}_{-I}) 
\cdot 
p(\boldsymbol{\tau}_{-I} | \sigma^2) 
\cdot 
p(\boldsymbol{\tau}_I | \boldsymbol{\tau}_{-I}, \sigma^2) 
\cdot 
p(\sigma^2) 
\cdot 
p(\boldsymbol{\tau'}_I | \boldsymbol{\tau}_{-I}, \sigma^2)}
$$
Since we only propose new values for $\boldsymbol{\tau'}_I$ we have that $\boldsymbol{\tau'}_{-I}=\boldsymbol{\tau}_{-I}$, inserting this in the expression above we get,

$$
=\frac
{p(\boldsymbol{y}_I | \boldsymbol{\tau'}_I) 
\cdot
p(\boldsymbol{y}_{-I} | \boldsymbol{\tau}_{-I}) 
\cdot 
p(\boldsymbol{\tau}_{-I} | \sigma^2) 
\cdot 
p(\boldsymbol{\tau'}_{I} | \boldsymbol{\tau}_{-I}, \sigma^2) 
\cdot 
p(\sigma^2) 
\cdot 
p(\boldsymbol{\tau}_I | \boldsymbol{\tau}_{-I}, \sigma^2)}
{p(\boldsymbol{y}_I | \boldsymbol{\tau}_I) 
\cdot
p(\boldsymbol{y}_{-I} | \boldsymbol{\tau}_{-I}) 
\cdot 
p(\boldsymbol{\tau}_{-I} | \sigma^2) 
\cdot 
p(\boldsymbol{\tau}_I | \boldsymbol{\tau}_{-I}, \sigma^2) 
\cdot 
p(\sigma^2) 
\cdot 
p(\boldsymbol{\tau'}_I | \boldsymbol{\tau}_{-I}, \sigma^2)}
$$
Here almost all the terms cancel out leaving giving us with
$$
\begin{aligned}
\alpha
= min(1, 
\frac
{p(\boldsymbol{y}_I | \boldsymbol{\tau'}_I) }
{p(\boldsymbol{y}_I | \boldsymbol{\tau}_I) })
\end{aligned}
$$






